# Content-Based Filtering with Neural Networks

Content-Based Filtering recommends items based on matching the **features of a user** to the **features of an item**. By using a neural network, this approach can learn complex, non-linear relationships between users and items to generate accurate predictions.

## 1. Feature Representation and Prediction Model

The core of the neural network architecture is to transform the potentially high-dimensional and disparate feature vectors of users and movies into **low-dimensional, unified embedding vectors** ($\mathbf{v}_{\text{u}}^{(j)}$ and $\mathbf{v}_{\text{m}}^{(i)}$).

| Vector | Description | Example Dimension |
| :--- | :--- | :--- |
| $\mathbf{x}_{\text{u}}^{(j)}$ | Raw feature vector for **user** $j$ (e.g., age, gender, country). | Varies |
| $\mathbf{x}_{\text{m}}^{(i)}$ | Raw feature vector for **movie** $i$ (e.g., year, genre vector). | Varies |
| $\mathbf{v}_{\text{u}}^{(j)}$ | **Embedding vector** for user $j$ learned by the Neural Network. | Length 32 |
| $\mathbf{v}_{\text{m}}^{(i)}$ | **Embedding vector** for movie $i$ learned by the Neural Network. | Length 32 |

The prediction is typically generated by taking the **dot product** of the two embedding vectors and passing the result through a non-linear activation function $g(\cdot)$ (like the Sigmoid function, especially for predicting a probability or a binary outcome).

$$
\hat{y}^{(i, j)} = g\left( (\mathbf{v}_{\text{u}}^{(j)})^T \mathbf{v}_{\text{m}}^{(i)} \right)
$$

* **Prediction Context:** If the model predicts a probability that $y^{(i, j)}=1$ (e.g., probability of a high rating or purchase), then $g(\cdot)$ is the Sigmoid function.

## 2. Neural Network Architecture

The architecture uses separate neural network paths for the user features and the movie features:

1.  **User Path:** $\mathbf{x}_{\text{u}}^{(j)}$ is fed into a sequence of layers (e.g., Dense layers, ReLU activation) to output the user embedding vector $\mathbf{v}_{\text{u}}^{(j)}$.
2.  **Movie Path:** $\mathbf{x}_{\text{m}}^{(i)}$ is fed into its own sequence of layers to output the movie embedding vector $\mathbf{v}_{\text{m}}^{(i)}$.
3.  **Output:** The two final vectors, $\mathbf{v}_{\text{u}}^{(j)}$ and $\mathbf{v}_{\text{m}}^{(i)}$, must have the **same dimension** (e.g., 32) so their dot product can be computed.

## 3. Cost Function (Loss)

The model is trained by minimizing the regularized squared error between the predicted rating and the actual rating, summing only over the movies the user has rated ($r(i, j)=1$).

$$
J = \sum_{(i, j): r(i, j)=1} \left( (\mathbf{v}_{\text{u}}^{(j)})^T \mathbf{v}_{\text{m}}^{(i)} - y^{(i, j)} \right)^2 + \text{NN Regularization}
$$

* **NN Regularization:** This includes L2 regularization on the weights of the neural network layers (not explicitly shown in the formula above, but critical for preventing overfitting).

---

## 4. Item Similarity

A useful outcome of this approach is the ability to find items similar to a given item $i$ by computing the distance between their learned embedding vectors.

The similarity between movie $i$ and movie $k$ is inversely related to their **squared Euclidean distance**:

$$
\text{Similarity} \propto \frac{1}{\| \mathbf{v}_{\text{m}}^{(k)} - \mathbf{v}_{\text{m}}^{(i)} \|^2}
$$

* **Pre-computation:** The similarity values for all pairs of movies ($\mathbf{v}_{\text{m}}^{(k)}$ vs. $\mathbf{v}_{\text{m}}^{(i)}$) can be **pre-computed ahead of time** to speed up retrieval during live recommendations.

---

## 5. The Two-Step Recommendation System (Retrieval and Ranking)

Large-scale recommendation systems often separate the process into two phases to balance performance (speed) and accuracy.

### Step A: Retrieval (Candidate Generation)

The goal is to generate a large, plausible list of candidate items ($100s$ or $1000s$) very **quickly**. This is typically done using simple, fast heuristics.

**Example Retrieval Heuristics:**
1.  **Item-to-Item Similarity:** For each of the user's last $N$ watched movies, find the $K$ most similar movies using the pre-computed $\mathbf{v}_{\text{m}}$ distances. (e.g., Last 10 movies $\implies$ 10 most similar).
2.  **Popularity/Aggregate:** Identify top $N$ items based on aggregated features (e.g., top 10 movies in the user's most viewed 3 genres, or top 20 movies in the user's country).
3.  **Combine and Filter:** Combine all retrieved items into a single list, removing **duplicates** and items the user has **already watched/purchased**.

### Step B: Ranking

The goal is to take the list of candidates from Retrieval and **rank them accurately** to show the user the most relevant items first. This uses the more complex, learned model.

* **Process:** For every candidate movie $i$ in the retrieved list, the full learned model is used to compute the precise predicted rating: $\hat{y}^{(i, j)} = g\left( (\mathbf{v}_{\text{u}}^{(j)})^T \mathbf{v}_{\text{m}}^{(i)} \right)$.
* **Display:** The candidates are sorted by their predicted rating $\hat{y}^{(i, j)}$ and the top $N$ items are displayed to the user.

### Optimizing the Trade-Off

* **Trade-Off:** Retrieving more items results in better performance (higher chance of finding a good match) but slower recommendations due to the large list passed to the Ranker.
* **Offline Experimentation:** To analyze this trade-off, carry out **offline experiments** to see if retrieving additional items results in a higher likelihood of displaying relevant recommendations. For instance, evaluate if the probability $P(y^{(i, j)}=1 \text{ of items displayed})$ increases significantly enough to justify the increased latency.
